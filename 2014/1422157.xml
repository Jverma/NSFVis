<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CIF: Small: Weakly Supervised Learning</AwardTitle>
    <AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2017</AwardExpirationDate>
    <AwardAmount>498210</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computer and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John Cozzens</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Traditional approaches to pattern recognition require access to labeled training data, consisting of known instances of each class under consideration. Such methods are known as "supervised" because the training labels are assumed to be correct. In many pattern recognition applications, however, precise label information is difficult or impossible to obtain. This research examines classification tasks involving contaminated training data, wherein training examples for some or all classes of interest are contaminated by examples of other classes. Applications include document classification, nuclear nonproliferation, network intrusion detection, drug design, and image and video annotation. When standard classification algorithms are applied in these settings, suboptimal classifiers result. Unfortunately, there currently exists no satisfactory theoretical or methodological framework that simultaneously addresses such classification problems characterized by contaminated data. &lt;br/&gt;&lt;br/&gt;To address this shortcoming, this research develops a novel framework for the decontamination of mutually contaminated probability distributions, together with associated estimation and classification methods. The decontamination strategy involves projecting observed distributions onto the convex hull of other observed distributions, and recovering the true distributions of interest from the residual of this projection. The projection is with respect to a statistical distance known as the separation distance, and under sufficient conditions on the amount of contamination and purity of the underlying class distributions, this projection procedure successfully recovers the class distributions. This in turn facilitates the design of optimal classifiers. The project examines in detail the problems of classification with noisy labels, anomaly detection, crowdsourcing, semi-supervised learning, domain adaptation, transfer learning, multiple instance learning, and learning from partial labels.</AbstractNarration>
    <MinAmdLetterDate>07/24/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>07/24/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1422157</AwardID>
    <Investigator>
      <FirstName>Clayton</FirstName>
      <LastName>Scott</LastName>
      <EmailAddress>clayscot@umich.edu</EmailAddress>
      <StartDate>07/24/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Ambuj</FirstName>
      <LastName>Tewari</LastName>
      <EmailAddress>tewaria@umich.edu</EmailAddress>
      <StartDate>07/24/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Michigan Ann Arbor</Name>
      <CityName>Ann Arbor</CityName>
      <ZipCode>481091274</ZipCode>
      <PhoneNumber>7347636438</PhoneNumber>
      <StreetAddress>3003 South State St.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Michigan</StateName>
      <StateCode>MI</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7797</Code>
      <Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7936</Code>
      <Text>SIGNAL PROCESSING</Text>
    </ProgramReference>
  </Award>
</rootTag>
