<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Medium: Integrating Humans and Computers for Image and Video Understanding</AwardTitle>
    <AwardEffectiveDate>08/21/2013</AwardEffectiveDate>
    <AwardExpirationDate>04/30/2016</AwardExpirationDate>
    <AwardAmount>529382</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>In this project, the research team explores several research challenges to exploit the relationship between images, video, and the people viewing this visual imagery. Areas of exploration include: 1) behavioral experiments to better understand the relationship between human viewers and imagery, 2) development of human-computer collaborative systems for image and video understanding that utilize automatic computer vision algorithms in conjunction with active and passive cues from human viewers, and 3) implementing retrieval and collection organization applications using our collaborative models.&lt;br/&gt;&lt;br/&gt;Billions of images and millions of videos are now available online via the infrastructure of amazingly successful companies from Google to Microsoft to Facebook. This wealth of visual data is creating considerable opportunities for communication and community, and tightening the social fabric of our world. In parallel to this explosion in online imagery, there is also an increasing proliferation of cameras viewing the user, from the ever present webcams peering out at us from our laptops, to cell phone cameras carried in our pockets wherever we go. This record of a user's viewing behavior, particularly of their eye, body movements, or descriptions, can provide enormous insight into how people interact with images or video, and can inform construction of more effective visual applications such as image or video retrieval. In addition, understanding what people recognize, attend to, or describe about an image or video is a necessary step toward high level goals of human centric image understanding that will have research benefits to many diverse fields, including computer vision and behavioral science.</AbstractNarration>
    <MinAmdLetterDate>06/10/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>06/10/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1445409</AwardID>
    <Investigator>
      <FirstName>Tamara</FirstName>
      <LastName>Berg</LastName>
      <EmailAddress>tlberg@cs.unc.edu</EmailAddress>
      <StartDate>06/10/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of North Carolina at Chapel Hill</Name>
      <CityName>CHAPEL HILL</CityName>
      <ZipCode>275991350</ZipCode>
      <PhoneNumber>9199663411</PhoneNumber>
      <StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>North Carolina</StateName>
      <StateCode>NC</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7924</Code>
      <Text>MEDIUM PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
  </Award>
</rootTag>
