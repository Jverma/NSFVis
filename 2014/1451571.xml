<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: CortiCore - Exploring the Use of An Automata Processor as an MISD Accelerator</AwardTitle>
    <AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2016</AwardExpirationDate>
    <AwardAmount>150000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computer and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Almadena Y. Chtchelkanova</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A novel computational accelerator architecture - the Automata Processor -has recently been introduced by Micron, that extends the computational paradigm of non-deterministic finite automata with important new capabilities. This architecture is particularly well suited for tasks involving pattern matching. Preliminary results suggest speedups as high as 1000X are possible, especially applications that entail combinatorial search, i.e., searching among many possible patterns to find the best match. This project evaluates the suitability of this novel architecture for accelerating combinatorial search, using cortical learning algorithms (i.e., algorithms for machine learning that are inspired by observations and/or theories of how the brain works) as a case study. Until now, cortical learning algorithms have primarily been implemented only in software, which leads to solutions that are slow, large, expensive and power hungry, and thus limits their applicability. In particular, this project initially focuses on accelerating hierarchical temporal memory, a cortical learning algorithm that has recently been shown to be highly effective for analysis and integration of high-data-rate, multi-modal sensor and video data. It embodies many characteristics of a variety of combinatorial search tasks, combining and extending techniques from Bayesian networks, clustering, and decision trees. This project is the first to evaluate the ability of the "enhanced automata" paradigm to accelerate cortical learning algorithms, and one of the first to explore the capabilities of the Automata Processor. In the process of evaluating the best way to accelerate cortical learning algorithms, this project will yield insights into the suitability of the Automata Processor for other artificial intelligence algorithms. It will also lead to development of new algorithms, software libraries, programming guidelines, and a new programming interface, to help speed the mapping of other applications to the Automata Processor and future accelerators. It will also yield techniques to improve the performance, flexibility, and energy efficiency of future accelerators, and new insights into the design and programming of heterogeneous systems with diverse accelerator hardware units.&lt;br/&gt;&lt;br/&gt; This project has potential to lay the foundations for a novel acceleration framework that enables efficient solutions to a large set of intractable problems, with orders-of-magnitude improvements in performance and energy efficiency, and to guide development of future accelerators. As a consequence of these acceleration capabilities, portable, low-power artificial intelligence solutions could become ubiquitous. This project creates tools that facilitate research and product development involving accelerator-based computing. This project contributes to education and outreach through new course materials and assignments, hands-on research and training opportunities in cutting-edge acceleration paradigms, and new academic-industry collaborations.</AbstractNarration>
    <MinAmdLetterDate>08/06/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/06/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1451571</AwardID>
    <Investigator>
      <FirstName>Mircea</FirstName>
      <LastName>Stan</LastName>
      <EmailAddress>mircea@virginia.edu</EmailAddress>
      <StartDate>08/06/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Kevin</FirstName>
      <LastName>Skadron</LastName>
      <EmailAddress>skadron@cs.virginia.edu</EmailAddress>
      <StartDate>08/06/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Virginia Main Campus</Name>
      <CityName>CHARLOTTESVILLE</CityName>
      <ZipCode>229044195</ZipCode>
      <PhoneNumber>4349244270</PhoneNumber>
      <StreetAddress>P.O. BOX 400195</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Virginia</StateName>
      <StateCode>VA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7798</Code>
      <Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7941</Code>
      <Text>COMPUTER ARCHITECTURE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7942</Code>
      <Text>HIGH-PERFORMANCE COMPUTING</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7943</Code>
      <Text>PROGRAMMING LANGUAGES</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7944</Code>
      <Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8206</Code>
      <Text>Formal Methods and Verification</Text>
    </ProgramReference>
  </Award>
</rootTag>
